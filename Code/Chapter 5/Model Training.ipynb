{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doubt Page 126\n",
    "\n",
    "**Index**\n",
    "\n",
    "- [Problem Statement](#A-hot-problem)\n",
    "    - [Data Collection](#Gathering-Data)\n",
    "- [Gradient Descent in a nutshell](#Gradient-Descent-in-a-nutshell)\n",
    "- [How to Autograd?](#Using-Autograd)\n",
    "    - [Always zero your GRAD](#Grad-value-accumulates)\n",
    "- [Optimization models](#Optimization-models)\n",
    "- [Training and Validation sets](#Training-and-Validation-sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve the below problem to learn how to train model in PyTorch\n",
    "\n",
    "### A hot problem\n",
    "    We just got back from a trip to some obscure location, and we brought back a fancy, wall-mounted analog thermometer. \n",
    "    It looks great, and it’s a perfect fit for our living room. Its only flaw is that it doesn’t show units. Not to worry,\n",
    "    we’ve got a plan: we’ll build a dataset of readings and corresponding temperature values in our favorite units, choose \n",
    "    a model, adjust its weights iteratively until a measure of the error is low enough, and finally be able to interpret \n",
    "    the new readings in units we understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering Data\n",
    "\n",
    "    Here, the t_c values are temperatures in Celsius, and the t_u values are our unknown units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "plt.scatter(t_c, t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a simple linear model and calculating mean squared error loss \n",
    "\n",
    "def model(t_u, w, b):\n",
    "    return w * t_u + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent in a nutshell\n",
    "    \n",
    "    Gradient descent is not that different from the scenario we just described. The idea is to compute the rate of change of\n",
    "    the loss with respect to each parameter, and modify each parameter in the direction of decreasing loss.\n",
    "\n",
    "This is saying that in the neighborhood of the current values of *w* and *b*, a unit increase in *w* leads to some change in the loss. If the change is **negative**, then we need to **increase** *w* to minimize the loss, whereas if the change is **positive**, we need to **decrease** *w*. By how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weight and bias.\n",
    "\n",
    "w = torch.ones(())\n",
    "b = torch.zeros(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the rate of change and updating weights\n",
    "\n",
    "loss_rate_of_change_w = \\\n",
    "(loss_fn(model(t_u, w + delta, b), t_c) -\n",
    "loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)\n",
    "\n",
    "w = w - learning_rate * loss_rate_of_change_w\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating bias\n",
    "\n",
    "loss_rate_of_change_b = \\\n",
    "(loss_fn(model(t_u, w, b + delta), t_c) -\n",
    "loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n",
    "\n",
    "b = b - learning_rate * loss_rate_of_change_b\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)               # The division is from the derivative of mean.\n",
    "    return dsq_diffs\n",
    "\n",
    "def dmodel_dw(t_u, w, b):\n",
    "    return t_u\n",
    "\n",
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0\n",
    "\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])    # The summation is the reverse of the\n",
    "                                                            # broadcasting we implicitly do when\n",
    "                                                            # applying the parameters to an entire\n",
    "                                                            # vector of inputs in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        \n",
    "        # Forward Pass\n",
    "        t_p = model(t_u, w, b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        \n",
    "        # Backward Pass\n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_un = 0.1 * t_u # Normalizing input\n",
    "\n",
    "training_loop(\n",
    "n_epochs = 5,\n",
    "learning_rate = 1e-2,\n",
    "params = torch.tensor([1.0, 0.0]),\n",
    "t_u = t_un,\n",
    "t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "params = [1, 0]\n",
    "t_p = model(t_un, *params)\n",
    "fig = plt.figure(dpi=600)\n",
    "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
    "plt.ylabel(\"Temperature (°Celsius)\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograd\n",
    "\n",
    "    PyTorch tensors can remember where they come from, in terms of the operations and parent tensors that originated them, \n",
    "    and they can automatically provide the chain of derivatives of such operations with respect to their inputs. This means \n",
    "    we won’t need to derive our model by hand; given a forward expression, no matter how nested, PyTorch will \n",
    "    automatically provide the gradient of that expression with respect to its input parameters.\n",
    "    \n",
    "Notice the \n",
    "```python \n",
    "requires_grad=True \n",
    "``` \n",
    "parameter in the initialization below\n",
    "\n",
    "That argument is telling PyTorch to track the entire family tree of tensors resulting from operations on ```params``` the value of the derivative will be automatically populated as a ``` grad ``` attribute of the params tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grad value accumulates\n",
    "PyTorch would compute the derivatives of the loss throughout the chain of functions (the computation graph) and **accumulate** their values in the grad attribute of those tensors (the leaf nodes of the graph)\n",
    "\n",
    "So if backward was called earlier, the loss is evaluated again, backward is called again (as in any training loop), and the gradient at each leaf is accumulated (that is, summed) on top of the one computed at the previous iteration, which leads to an incorrect value for the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        loss.backward()\n",
    "        with torch.no_grad(): # AutoGrad Engine look away here\n",
    "            params -= learning_rate * params.grad\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "n_epochs = 5000,\n",
    "learning_rate = 1e-2,\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "t_u = t_un,\n",
    "t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization models\n",
    "\n",
    "Each optimizer exposes two methods: ```zero_grad``` and ```step```. **zero_grad** zeroes the ```grad``` attribute of all the parameters passed to the optimizer upon construction. **step** updates the value of those parameters according to the optimization strategy implemented by the specific optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD stands for stochastic gradient descent.\n",
    "\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Adam Optimizer.\n",
    "\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "training_loop(n_epochs = 5000, optimizer = optimizer, params = params, \n",
    "              t_u = t_u, t_c = t_c) # Not using scaled values as Adam is less sesitive to the scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        # Make sure we don't create computation graph for validation set\n",
    "        with torch.no_grad():\n",
    "            val_t_p = model(val_t_u, *params)\n",
    "            val_loss = loss_fn(val_t_p, val_t_c)\n",
    "            assert val_loss.requires_grad == False\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"f\" Validation loss {val_loss.item():.4f}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "training_loop(\n",
    "n_epochs = 3000,\n",
    "optimizer = optimizer,\n",
    "params = params,\n",
    "train_t_u = train_t_un,\n",
    "val_t_u = val_t_un,\n",
    "train_t_c = train_t_c,\n",
    "val_t_c = val_t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def calc_forward(t_u, t_c, is_train):\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
